{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea28097d-de45-4854-a507-58e3633d252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os, glob, datetime\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9444205e-c739-4faa-901c-665492e70119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a116a429-e564-4ecf-8fc9-c77fa4ee24bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = glob.glob(os.path.expanduser(\"~/Documents/projects/chatgpt-from-scratch/data/*.csv\"))[0]\n",
    "df = pd.read_csv(file, index_col=0).dropna(how=\"any\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee10e2-2ca8-4e7c-a47c-c6ecc8b77810",
   "metadata": {},
   "source": [
    "### Build tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d1c2f-4402-48d8-ab73-64931be301af",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"statement\"].tolist()\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(vocab_size=30000, min_frequency=3, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "tokenizer.train_from_iterator(text, trainer)\n",
    "\n",
    "tokenizer.save(\"../data/tokenizer-mental-health.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae8121-9cbb-484e-8317-9e5ec9237b2d",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a56aa11-c025-4ff7-8976-9491a072e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.2\n",
    "BATCH_SIZE = 64\n",
    "D_MODEL = 16\n",
    "FF_SIZE = 8\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b92ccd-cd65-4972-8dba-c58c3d93cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, statements, labels, tokenizer, max_length=1000):\n",
    "        self.statements = statements\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.statements)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        statement = self.statements[idx]\n",
    "        label = self.labels[idx]\n",
    "        tokens = self.tokenizer(statement)\n",
    "        if len(tokens) > self.max_length:\n",
    "            i_start = torch.randint(low=0, high=len(tokens) - self.max_length + 1, size=(1, )).item()\n",
    "            tokens = tokens[i_start:i_start+self.max_length]\n",
    "        tokens = torch.tensor(tokens)\n",
    "\n",
    "        return tokens, torch.tensor(label)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tokens, labels = zip(*batch)\n",
    "    tokens_padded = pad_sequence(tokens, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "    return tokens_padded, labels\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_classes):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        # self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.positional_embedding = nn.Embedding(max_length, d_model)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True, dropout=DROPOUT, dim_feedforward=FF_SIZE)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_encoder_layers)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "        # self.batch_norm = nn.BatchNorm1d(d_model)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src_positions = torch.arange(0, src.size(1), device=src.device).unsqueeze(0).expand(src.size(0), -1)\n",
    "        # src = self.embedding(src) * math.sqrt(self.embedding.embedding_dim)\n",
    "        src = self.embedding(src) + self.positional_embedding(src_positions)\n",
    "        # src = self.pos_encoder(src)\n",
    "        # src = self.batch_norm(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.mean(dim=1)  # Global average pooling\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d4248-a1c3-469a-a36c-619f4449627d",
   "metadata": {},
   "source": [
    "### Eval tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d45327-555e-4e75-8ed1-322861cb3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"data/tokenizer-mental-health.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a741a34a-05ae-40ed-9332-a2ef1f63c3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['on', 'my', 'gosh']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"on my gosh\").tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f424c82-4c56-4e8b-80c1-be736acaae38",
   "metadata": {},
   "source": [
    "#### Augument data to make data balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3cc6fb4-61b9-446e-802b-8d763d3e2d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anxiety</th>\n",
       "      <td>3841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bipolar</th>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depression</th>\n",
       "      <td>15404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>16343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personality disorder</th>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stress</th>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suicidal</th>\n",
       "      <td>10652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      statement\n",
       "status                         \n",
       "Anxiety                    3841\n",
       "Bipolar                    2777\n",
       "Depression                15404\n",
       "Normal                    16343\n",
       "Personality disorder       1077\n",
       "Stress                     2587\n",
       "Suicidal                  10652"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"status\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b5866-4fd7-4ff1-acf7-272d4c623888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety, 3841\n",
      "Suicidal, 10652\n",
      "Stress, 2587\n",
      "Bipolar, 2777\n",
      "Personality disorder, 1077\n"
     ]
    }
   ],
   "source": [
    "threshold = df.groupby(\"status\").count().quantile(0.7)\n",
    "\n",
    "threshold.values[0]\n",
    "\n",
    "for status in df[\"status\"].unique():\n",
    "    _data = df[df[\"status\"] == status]\n",
    "    if len(_data) < threshold.values[0]:\n",
    "        print(f\"{status}, {len(_data)}\")\n",
    "        n = threshold.values[0] // len(_data)\n",
    "        for _ in range(int(n)):\n",
    "            df = pd.concat((df, _data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a3be1db-56f0-4843-bf00-9bdc0e833fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anxiety</th>\n",
       "      <td>15364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bipolar</th>\n",
       "      <td>13885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depression</th>\n",
       "      <td>15404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>16343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personality disorder</th>\n",
       "      <td>11847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stress</th>\n",
       "      <td>12935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suicidal</th>\n",
       "      <td>21304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      statement\n",
       "status                         \n",
       "Anxiety                   15364\n",
       "Bipolar                   13885\n",
       "Depression                15404\n",
       "Normal                    16343\n",
       "Personality disorder      11847\n",
       "Stress                    12935\n",
       "Suicidal                  21304"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"status\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce10b40b-94cd-451e-b26d-644aaa0622cf",
   "metadata": {},
   "source": [
    "#### Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9ba19-3e21-498e-819d-6a8998cb8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = int(df[\"statement\"].apply(len).quantile(0.9))\n",
    "max_length = 1562\n",
    "\n",
    "statements = df[\"statement\"].values\n",
    "labels = df[\"status\"].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "train_statements, val_statements, train_labels, val_labels = train_test_split(statements, encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb3c9066-01bb-47d2-973e-6f0bb1938b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    return tokenizer.encode(text).ids\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(train_statements, train_labels, tokenizer=simple_tokenizer)\n",
    "val_dataset = SentimentDataset(val_statements, val_labels, tokenizer=simple_tokenizer)\n",
    "whole_dataset = SentimentDataset(statements, encoded_labels, tokenizer=simple_tokenizer)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "whole_loader = DataLoader(whole_dataset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ce50368-1cfc-47ce-99ff-e338d97a5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "vocab_size = 30000  # Based on simple_tokenizer, you may need to adjust this based on your tokenizer\n",
    "model = CustomTransformerModel(vocab_size=vocab_size, d_model=16, nhead=2, num_encoder_layers=4, num_classes=len(label_encoder.classes_)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653ce83-4ed8-4eb8-b5c5-1a5b1a0834f5",
   "metadata": {},
   "source": [
    "### Model training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322e966-118d-477c-ab50-d2eec078b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-8)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = EPOCH\n",
    "model.train()\n",
    "\n",
    "write = open(\"epoches.csv\", \"w\")\n",
    "writer = csv.writer(write)\n",
    "writer.writerow([f\"Dropout: {DROPOUT}, Batch_size: {BATCH_SIZE}, D_model: {D_MODEL}, Feed forward: {FF_SIZE}\"])\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"{datetime.datetime.now().strftime('%H:%M:%S %p')}: start training epoch {epoch+1}...\")\n",
    "        total_losses = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_losses += loss.item()                \n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        training_loss = total_losses/len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "              \n",
    "        # Optional: Evaluate on the validation set after each epoch\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)        \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Training loss: {training_loss:.6f}, Train Accuracy: {train_accuracy:.2f}%; Validation Loss: {val_loss/len(val_loader):.6f}, Accuracy: {100 * correct / total:.2f}%, Learning rate: {scheduler.get_last_lr()[0]}')\n",
    "        writer.writerow([f'Epoch {epoch+1}, Training loss: {training_loss:.6f}, Train Accuracy: {train_accuracy:.2f}%; Validation Loss: {val_loss/len(val_loader):.6f}, Accuracy: {100 * correct / total:.2f}%, Learning rate: {scheduler.get_last_lr()[0]}'])\n",
    "        model.train()\n",
    "except KeyboardInterrupt as e:\n",
    "    raise e\n",
    "finally:\n",
    "    write.close()\n",
    "    torch.save(model.state_dict(), \"model_state.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c4660-f4e0-4994-b828-fbc9193413ee",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9a90e67-4c17-43ee-befc-aeb785e812f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"model_state.pth\", weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2566e349-f5c1-429b-ac6a-790eba872392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel(\n",
       "  (embedding): Embedding(30000, 16)\n",
       "  (positional_embedding): Embedding(1562, 16)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=8, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=8, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=16, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "819b6807-11ed-46b7-aa50-e1505fde0694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel(\n",
       "  (embedding): Embedding(30000, 16)\n",
       "  (positional_embedding): Embedding(1562, 16)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=8, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=8, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=16, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9e13247-839c-43f5-8b71-d9ab30f854c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression\n"
     ]
    }
   ],
   "source": [
    "input_statement = \"I feel tired all the time\"\n",
    "\n",
    "tokens = tokenizer.encode(input_statement)\n",
    "res = model(torch.tensor(tokens.ids).view(1, -1))\n",
    "_, label = torch.max(res, 1)\n",
    "result = label_encoder.inverse_transform(label)[0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d84f27d-fbab-4fc7-a77a-a36fd6f21667",
   "metadata": {},
   "source": [
    "#### Evaluation model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e29e79a4-50a9-42a0-b95a-b7ddfe055ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77e5c1a246842558b750b1570fb7ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.35%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for item, label_ in tqdm(whole_loader):\n",
    "        outputs = model(item)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += label_.size(0)\n",
    "        correct += (predicted == label_).sum().item()\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
